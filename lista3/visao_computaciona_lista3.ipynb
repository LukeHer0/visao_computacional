{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55f193e0",
   "metadata": {},
   "source": [
    "# Terceira lista de visão computacional\n",
    "# Lucas Heron Santos Anchieta\n",
    "# Ruan Tenório de Melo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfed609",
   "metadata": {},
   "source": [
    "## Importações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "5d74138c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "368ab35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(url, code = cv.IMREAD_COLOR):\n",
    "  resp = urllib.request.urlopen(url)\n",
    "  image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
    "  image = cv.imdecode(image, code)\n",
    "  return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a948fb9a",
   "metadata": {},
   "source": [
    "## 1. Escolha uma das metodologias que você implementou na segunda lista para gerar correspondências entre um par de imagens. Aplique-a em 5 pares de imagens (com sobreposição) para calcular suas homografias, e aplique-as para gerar panoramas entre os pares de imagens (um panorama por par).\n",
    "## Obs.: nessa questão, não é permitido usar a API de alto nível Stitcher.\n",
    "## Dica: use a função warpPerspective da OpenCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "2065e380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flan_matcher(des1, des2, index_params, search_params):\n",
    "  # Create FLANN matcher\n",
    "  flann = cv.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "  # Match descriptors\n",
    "  matches = flann.knnMatch(des1, des2, k=2)\n",
    "\n",
    "  \n",
    "\n",
    "  good_matches = []\n",
    "  ratio_threshold = 0.9\n",
    "  for m, n in matches:\n",
    "      if m.distance < ratio_threshold * n.distance:\n",
    "          good_matches.append(m)\n",
    "  good_matches = sorted(good_matches, key=lambda x: x.distance)\n",
    "\n",
    "  return good_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "b3b79398",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_matches_mpl(img1, keypoints1, img2, keypoints2, matches):\n",
    "    \"\"\"Draw matches using Matplotlib.\"\"\"\n",
    "\n",
    "    # Combine images horizontally\n",
    "    h1, w1 = img1.shape[:2]\n",
    "    h2, w2 = img2.shape[:2]\n",
    "    combined_img = np.zeros((max(h1, h2), w1 + w2, 3), dtype=np.uint8)\n",
    "    combined_img[:h1, :w1] = img1\n",
    "    combined_img[:h2, w1:] = img2\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.imshow(combined_img)\n",
    "    plt.axis('off')\n",
    "  \n",
    "    # Draw lines connecting the matches\n",
    "    offset = w1\n",
    "    for match in matches:\n",
    "        pt1 = keypoints1[match.queryIdx].pt\n",
    "        pt2 = keypoints2[match.trainIdx].pt\n",
    "        x1, y1 = int(pt1[0]), int(pt1[1])\n",
    "        x2, y2 = int(pt2[0] + offset), int(pt2[1])\n",
    "        plt.plot([x1, x2], [y1, y2], 'r-', linewidth=0.5)\n",
    "        plt.plot(x1, y1, 'bo', markersize=3)  # Mark keypoints\n",
    "        plt.plot(x2, y2, 'bo', markersize=3)\n",
    "\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "65b4be70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def descriptor_akaze(img):\n",
    "  akaze = cv.akaze_create()\n",
    "  # Detect keypoints and compute descriptors\n",
    "  kp, des = akaze.detectAndCompute(img, None)\n",
    "\n",
    "  return kp, des\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b63a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_homograph(kp1, kp2, matches): \n",
    "  src_pts = np.float32([ kp1[m.queryIdx].pt for m in matches ]).reshape(-1, 1, 2)\n",
    "  dst_pts = np.float32([ kp2[m.trainIdx].pt for m in matches ]).reshape(-1, 1, 2)\n",
    "  H, mask =  cv.findHomography(src_pts, dst_pts, cv.RANSAC, 5.0)\n",
    "\n",
    "  return H, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "38a4480f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_panorama(img1, img2):\n",
    "    img1_gray = cv.cvtColor(img1, cv.COLOR_BGR2GRAY)\n",
    "    img2_gray = cv.cvtColor(img2, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    FLANN_INDEX_KDTREE = 1\n",
    "    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "    search_params = dict(checks=50)\n",
    "    akaze = cv.AKAZE_create()\n",
    "\n",
    "    # Encontrar keypoints e descritores\n",
    "    kp1, des1 = akaze.detectAndCompute(img1_gray, None)\n",
    "    kp2, des2 = akaze.detectAndCompute(img2_gray, None)\n",
    "\n",
    "    \n",
    "    des1 = des1.astype(np.float32)\n",
    "    des2 = des2.astype(np.float32)\n",
    "\n",
    "    good_matches = flan_matcher(des1, des2, index_params, search_params)\n",
    "\n",
    "    # Find homography\n",
    "    M, _ = get_homograph(kp1, kp2, good_matches)\n",
    "\n",
    "    if M is None:\n",
    "        return np.hstack((img1, img2))\n",
    "    img1_height, img1_width = img1.shape[:2]\n",
    "    img2_height, img2_width = img2.shape[:2]\n",
    "    # Get the corners of img1\n",
    "    corners1 = np.array([[0, 0], [img1_width, 0], [img1_width, img1_height], [0, img1_height]], dtype=np.float32)\n",
    "    # Transform corners of img1 to img2's perspective\n",
    "    corners1_transformed = cv.perspectiveTransform(corners1.reshape(-1, 1, 2), M)\n",
    "    # Get the corners of img2\n",
    "    corners2 = np.array([[0, 0], [img2_width, 0], [img2_width, img2_height], [0, img2_height]], dtype=np.float32)\n",
    "\n",
    "    # Combine corners\n",
    "    all_corners = np.concatenate((corners1_transformed, corners2.reshape(-1, 1, 2)), axis=0)\n",
    "    # Get the bounding box of all corners\n",
    "    [x_min, y_min] = np.int32(all_corners.min(axis=0).ravel())\n",
    "    [x_max, y_max] = np.int32(all_corners.max(axis=0).ravel())\n",
    "    # Adjust the translation matrix to include the bounding box\n",
    "\n",
    "    # Create a new image with the size of the bounding box\n",
    "    panorama_width = x_max - x_min\n",
    "    panorama_height = y_max - y_min\n",
    "    panorama = np.zeros((panorama_height, panorama_width, 3), dtype=np.uint8)\n",
    "    translation_dist = [-x_min, -y_min]\n",
    "      # Create a translation matrix to shift the panorama to the correct position\n",
    "    translation_matrix = np.array([[1, 0, -x_min], [0, 1, -y_min], [0, 0, 1]])\n",
    "    # Warp img1 to the panorama\n",
    "    panorama = cv.warpPerspective(img1, translation_matrix @ M, (panorama_width, panorama_height))\n",
    "    \n",
    "    # Combine the two warped images\n",
    "    # panorama = cv.addWeighted(panorama1, 0.5, panorama2, 0.5, 0)\n",
    "    # Return the panorama\n",
    "    panorama[translation_dist[1]:img2_height + translation_dist[1], translation_dist[0]:img2_width + translation_dist[0]] = img2\n",
    "    return panorama\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "b9f82433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# orb.cv.ORB_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e363a497",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv.imread('./img/sofa1.jpg')\n",
    "img1 = cv.cvtColor(img1, cv.COLOR_BGR2RGB)\n",
    "\n",
    "# h, w = img1.shape[:2]\n",
    "\n",
    "# img1 = cv.resize(img1, (w//8, h//8), interpolation=cv.INTER_CUBIC)\n",
    "\n",
    "plt.imshow(img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910bc585",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = cv.imread('./img/sofa2.jpg')\n",
    "img2 = cv.cvtColor(img2, cv.COLOR_BGR2RGB)\n",
    "\n",
    "plt.imshow(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "b16425c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(compute_panorama(img1, img2))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "216f6cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# M, mask = get_homograph(kp1, kp2, flan_matcher)\n",
    "\n",
    "# h1, w1 = img1.shape[:2]\n",
    "# h2, w2 = img2.shape[:2]\n",
    "\n",
    "# corners_img1 = np.float32([[0,0], [0,h1], [w1,h1], [w1,0]]).reshape(-1,1,2)\n",
    "# warped_corners_img1 = cv.perspectiveTransform(corners_img1, M)\n",
    "\n",
    "# all_corners = np.concatenate((warped_corners_img1, np.float32([[0,0], [0,h2], [w2,h2], [w2,0]]).reshape(-1,1,2)), axis=0)\n",
    "\n",
    "# [xmin, ymin] = np.int32(all_corners.min(axis=0).ravel() - 0.5)\n",
    "# [xmax, ymax] = np.int32(all_corners.max(axis=0).ravel() + 0.5)\n",
    "\n",
    "# translation_dist = [-xmin, -ymin]\n",
    "# H_translation = np.array([[1, 0, translation_dist[0]],\n",
    "#                           [0, 1, translation_dist[1]],\n",
    "#                           [0, 0, 1]])\n",
    "\n",
    "# panorama = cv.warpPerspective(img1, H_translation @ M, (xmax - xmin, ymax - ymin))\n",
    "\n",
    "# panorama[translation_dist[1]:h2 + translation_dist[1], translation_dist[0]:w2 + translation_dist[0]] = img2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7257b413",
   "metadata": {},
   "source": [
    "## 2. Repita a questão anterior com 5 trios de imagens (com sobreposição 2 a 2), alinhando as imagens no plano da primeira imagem. Repita o mesmo alinhando no plano da segunda imagem, e da terceira imagem. Note que aqui será necessário compor as transformações de homografia em alguns casos, ou calcular inversas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "db3e721f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv.imread('./img/rua1_resized.jpg')\n",
    "img1 = cv.cvtColor(img1, cv.COLOR_BGR2RGB)\n",
    "img1 = cv.flip(img1, -1)\n",
    "\n",
    "img2 = cv.imread('./img/rua2_resized.jpg')\n",
    "img2 = cv.cvtColor(img2, cv.COLOR_BGR2RGB)\n",
    "img2 = cv.flip(img2, -1)\n",
    "\n",
    "img3 = cv.imread('./img/rua3_resized.jpg')\n",
    "img3 = cv.cvtColor(img3, cv.COLOR_BGR2RGB)\n",
    "img3 = cv.flip(img3, -1)\n",
    "\n",
    "panorama1 = compute_panorama(img1, img2)\n",
    "plt.imshow(cv.flip(panorama1, -1))\n",
    "plt.title('Panorama Part 1 (2 images)') \n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "panorama2 = compute_panorama(img3, panorama1)\n",
    "panorama2 = cv.flip(panorama2, -1)\n",
    "plt.title('Panorama Part 2 (3 images)')\n",
    "plt.axis('off')\n",
    "plt.imshow(panorama2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04161074",
   "metadata": {},
   "source": [
    "## 3. Considere a imagem soccer.jpg (./img/soccer.jpg) em anexo no Google Classroom. Considere que o campo da imagem tenha as dimensões dadas pela figura (./img/q3_anexo.png)\n",
    "## Gere manualmente correspondências entre a imagem e um mapa 2d com dimensões dadas pela figura. Calcule a homografia resultante e aplique na imagem original. Exiba o resultado. Dica: leia este tutorial (https://medium.com/acmvit/how-to-project-an-image-in-perspective-view-of-a-background-image-opencv-python-d101bdf966bc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "56b6c60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"./img/soccer.jpg\")\n",
    "field = cv.imread(\"./img/q3_anexo.png\")\n",
    "\n",
    "h_field, w_field = field.shape[:2]\n",
    "resized_img = cv.resize(img, (w_field, h_field))\n",
    "\n",
    "positions = []\n",
    "count = 0\n",
    "pts1 = []\n",
    "pts2 = []\n",
    "current_image = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "951ecacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_circle(event, x, y, flags, param):\n",
    "    global positions, count, current_image\n",
    "\n",
    "    if event == cv.EVENT_LBUTTONUP:\n",
    "        if count >= 4:\n",
    "            return\n",
    "        cv.circle(current_image, (x,y), 2, (255, 0, 0), -1)\n",
    "\n",
    "        positions.append((x,y))\n",
    "        \n",
    "        count += 1\n",
    "        if count > 1:\n",
    "            cv.line(current_image, positions[-2], positions[-1], \n",
    "                   (255, 0, 255), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "3a3c0c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_image = field.copy()\n",
    "positions = []\n",
    "count = 0\n",
    "cv.namedWindow('image')\n",
    "cv.setMouseCallback('image', draw_circle)\n",
    "\n",
    "while(True):\n",
    "    cv.imshow('image', current_image)\n",
    "    k = cv.waitKey(20) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "pts1 = np.float32(positions)\n",
    "print(\"Collected points:\\n\", pts1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "6f9c316b",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_image = resized_img.copy()\n",
    "positions = []\n",
    "count = 0\n",
    "cv.namedWindow('image')\n",
    "cv.setMouseCallback('image', draw_circle)\n",
    "\n",
    "while(True):\n",
    "    cv.imshow('image', current_image)\n",
    "    k = cv.waitKey(20) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "cv.destroyAllWindows()\n",
    "\n",
    "pts2 = np.float32(positions)\n",
    "print(\"Collected points:\\n\", pts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "6920187a",
   "metadata": {},
   "outputs": [],
   "source": [
    "h, _ = cv.findHomography(pts2, pts1, cv.RANSAC, 5.0)\n",
    "print(f\"Matriz de homografia: \\n\", h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c1e66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_field = np.zeros((h_field, w_field), dtype=np.uint8)\n",
    "cv.fillConvexPoly(mask_field, pts1.astype(int), 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dff7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_img = np.zeros((h_field, w_field), dtype=np.uint8)\n",
    "cv.fillConvexPoly(mask_img, pts2.astype(int), 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e267de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "warped_img = cv.warpPerspective(resized_img, h, (w_field, h_field))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2123c966",
   "metadata": {},
   "outputs": [],
   "source": [
    "field_bg = cv.bitwise_and(field, field, mask=cv.bitwise_not(mask_field))\n",
    "img_fg = cv.bitwise_and(warped_img, warped_img, mask=mask_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10adabe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = cv.add(field_bg, img_fg)\n",
    "\n",
    "# Mostra o resultado\n",
    "while(True):\n",
    "    cv.imshow('image', result)\n",
    "    k = cv.waitKey(20) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c734c285",
   "metadata": {},
   "source": [
    "## 4. Leia o seguinte tutorial de calibração de câmera: https://docs.opencv.org/4.x/dc/dbb/tutorial_py_calibration.html\n",
    "## Você vai precisar de um tabuleiro de xadrez (pode imprimir numa folha A4, e colar num papelão ou emplastificar para a geometria ficar fixa). Meça as dimensões do seu tabuleiro para calibrar a câmera, considerando que o tabuleiro sempre está no plano z = 0, e que o canto inferior esquerdo do tabuleiro é a origem (0, 0, 0). Após calibrar a câmera, vamos incluir um objeto virtual na imagem. Considere a seguinte equação paramétrica do círculo centrado no ponto (1.5W, 1.5H, 0), com raio r = 0.5W e contido no plano z = 0, onde H e W são a as medidas da altura e largura do tabuleiro:\n",
    "\n",
    "## p(θ) = (r cos θ + 1.5W, r sen θ + 1.5H, 0).\n",
    "\n",
    "## Se assegure de que o círculo apareça na imagem, de acordo com a posição do xadrez na imagem. Para desenhar o círculo, varie o valor do angulo θ entre 0 e 2π para amostrar alguns pontos, e projete-os na imagem. Repita isso 3 vezes, variando o ângulo entre o vetor normal do tabuleiro e o eixo principal da câmera."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
